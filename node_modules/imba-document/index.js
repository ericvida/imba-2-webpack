function computeLineOffsets(text,isAtLineStart,textOffset){
	
	if (textOffset === undefined) {
		
		textOffset = 0;
	}	
	var result = isAtLineStart ? [textOffset] : [];
	var i = 0;
	while (i < text.length){
		
		var ch = text.charCodeAt(i);
		if (ch === 13 || ch === 10) {
			
			if (ch === 13 && (i + 1 < text.length) && text.charCodeAt(i + 1) === 10) {
				
				i++;
			}			result.push(textOffset + i + 1);
		}		i++;
	}	return result;
}
function getWellformedRange(range){
	
	var start = range.start;
	var end = range.end;
	if (start.line > end.line || start.line === end.line && start.character > end.character) {
		
		return {start: end,end: start};
	}	return range;
}
function editIsFull(e){
	
	return e !== undefined && e !== null && typeof e.text === 'string' && e.range === undefined;
}

const newline = String.fromCharCode(172);

// var eolpop = [/@newline/, token: '@rematch', next: '@pop']
var eolpop = [/^/,{token: '@rematch',next: '@pop'}];

var grammar = {
	defaultToken: 'invalid',
	ignoreCase: false,
	tokenPostfix: '',
	brackets: [
		{open: '{',close: '}',token: 'delimiter.curly'},
		{open: '[',close: ']',token: 'delimiter.square'},
		{open: '(',close: ')',token: 'delimiter.parenthesis'}
	],
	keywords: [
		'def','and','or','is','isnt','not','on','yes','@','no','off',
		'true','false','null','this','self','as',
		'new','delete','typeof','in','instanceof',
		'return','throw','break','continue','debugger',
		'if','elif','else','switch','for','while','do','try','catch','finally',
		'class','extends','super',
		'undefined','then','unless','until','loop','of','by','when',
		'tag','prop','attr','export','import','extend',
		'var','let','const','require','isa','await'
	],
	boolean: ['true','false','yes','no','undefined'],
	contextual_keywords: [
		'from','global','attr'
	],
	operators: [
		'=','!','~','?',':','!!',
		'&','|','^','%','<<',
		'>>','>>>','+=','-=','*=','/=','&=','|=','?=',
		'^=','%=','<<=','>>=','>>>=','..','...','||='
	],
	logic: [
		'>','<','==','<=','>=','!=','&&','||','===','!=='
	],
	ranges: ['..','...'],
	dot: ['.'],
	math: [
		'+','-','*','/','++','--'
	],
	
	// we include these common regular expressions
	symbols: /[=><!~?&%|+\-*\/\^\.,\:]+/,
	escapes: /\\(?:[abfnrtv\\"'$]|x[0-9A-Fa-f]{1,4}|u[0-9A-Fa-f]{4}|U[0-9A-Fa-f]{8})/,
	postaccess: /(:(?=\w))?/,
	ivar: /\@[a-zA-Z_]\w*/,
	constant: /[A-Z][A-Za-z\d\-\_]*/,
	className: /[A-Z][A-Za-z\d\-\_]*|[A-Za-z\d\-\_]+/,
	methodName: /[A-Za-z\_][A-Za-z\d\-\_]*\=?/,
	identifier: /[a-z_][A-Za-z\d\-\_]*/,
	anyIdentifier: /[A-Za-z_\$][A-Za-z\d\-\_\$]*/,
	esmIdentifier: /\@?[A-Za-z_\$][A-Za-z\d\-\_\$]*/,
	propertyPath: /(?:[A-Za-z_\$][A-Za-z\d\-\_\$]*\.)?(?:[A-Za-z_\$][A-Za-z\d\-\_\$]*)/,
	tagNameIdentifier: /(?:[\w\-]+\:)?\w+(?:\-\w+)*/,
	variable: /[\w\$]+(?:-[\w\$]*)*/,
	varKeyword: /var|let|const/,
	newline: new RegExp(newline),
	tagIdentifier: /-*[a-zA-Z][\w\-]*/,
	
	regEx: /\/(?!\/\/)(?:[^\/\\]|\\.)*\/[igm]*/,
	
	regexpctl: /[(){}\[\]\$\^|\-*+?\.]/,
	regexpesc: /\\(?:[bBdDfnrstvwWn0\\\/]|@regexpctl|c[A-Z]|x[0-9a-fA-F]{2}|u[0-9a-fA-F]{4})/,
	
	// The main tokenizer for our languages
	tokenizer: {
		root: [
			{include: '@body'}
		],
		
		common: [
			{include: '@whitespace'}
		],
		
		legacy_access: [
			[/(\:)(\@?@anyIdentifier)/,['operator.dot.legacy','property']]
		],
		
		spread: [
			[/\.\.\./,'operator.spread'],
			[/(\*)(?=[\w\$])/,'operator.spread.legacy']
		],
		
		expression: [
			{include: 'legacy_access'},
			{include: 'spread'},
			{include: 'do'},
			{include: 'access'},
			{include: 'identifiers'},
			{include: 'tag_start'},
			{include: 'string_start'},
			{include: 'regexp_start'},
			{include: 'object_start'},
			{include: 'array_start'},
			{include: 'number'},
			{include: 'comments'},
			{include: 'common'},
			{include: 'operators'},
			{include: 'decorator'},
			
			[/\(/,'delimiter.parens.open','@parens']
		],
		
		expressable: [
			{include: 'catch'}
		],
		
		catch: [
			[/(catch)(\s)(@anyIdentifier)/,['keyword.catch','white','variable.let']]
		],
		
		do: [
			[/(do)(\()/,[{token: 'keyword.$1'},{token: 'argparam.open',next: '@var_parens.argparam'}]]
		],
		
		access: [
			[/(\.)(\@?@anyIdentifier)(\s+)(?=\S)/,['operator.dot','property',{token: 'white',next: '@implicit_params'}]],
			[/(\.)(\@?@anyIdentifier)/,['operator.dot','property']]
		],
		
		decorator: [
			[/\@(@anyIdentifier)?/,'decorator']
		],
		
		implicit_params: [
			eolpop,
			[/[\)\}\]]/,{token: '@rematch',next: '@pop'}],
			{include: 'expression'},
			[/\,/,'delimiter']
		],
		
		identifiers: [
			[/\$\w+\$/,'identifier.env'],
			[/\$\d+/,'identifier.special'],
			[/(@constant)/,'identifier.constant'],
			[/(@identifier)/,{cases: {
				this: 'this',
				self: 'self',
				'$1@boolean': {token: 'boolean.$1'},
				'$1@keywords': {token: 'keyword.$1'},
				'@default': 'identifier'
			}}],
			{include: 'type_start'}
		],
		
		type_start: [
			[/\\/,'type.start','@type.0']
		],
		
		type: [
			eolpop,
			[/\[/,'type','@type.]'],
			[/\(/,'type','@type.)'],
			[/\{/,'type','@type.}'],
			[/\</,'type','@type.>'],
			[/\,|\s/,{
				cases: {
					'$S2==0': {token: '@rematch',next: '@pop'},
					'@default': 'type'
				}
			}],
			[/[\]\}\)\>]/,{
				cases: {
					'$1==$S2': {token: 'type',next: '@pop'},
					'@default': {token: '@rematch',next: '@pop'}
				}
			}],
			[/[\w\-\$]+/,'type']
		],
		
		parens: [
			[/\)/,'delimiter.parens.close','@pop'],
			{include: 'var_expr'},
			{include: 'expression'},
			[/\,/,'delimiterz']
		],
		
		statements: [
			{include: 'var_statement'},
			{include: 'forin_statement'},
			{include: 'prop_statement'},
			{include: 'def_statement'},
			{include: 'class_statement'},
			{include: 'tag_statement'},
			{include: 'import_statement'},
			{include: 'expressable'},
			{include: 'expression'}
		],
		
		prop_statement: [
			[/(attr|prop)(\s)(@identifier)/,[{token: 'keyword.$1'},'white.propname',{token: 'identifier.propname'}]]
		],
		
		var_statement: [
			[/(@varKeyword)(?=\s)/,'keyword.$1','@var_decl.$1']
		],
		
		var_expr: [
			[/(@varKeyword)(?=\s)/,'keyword.$1','@single_var_decl.$1']
		],
		
		var_parens: [
			[/\)/,'$S2.close','@pop'],
			{include: 'var_decl'}
		],
		
		forin_statement: [
			[/for( own)? /,'keyword.for','@forin_var_decl.let']
		],
		
		def_statement: [
			[/(def|set|get)(\s)(@propertyPath)(\s)(?=\{|\w|\[|\.\.\.|\*)/,[{token: 'keyword.$1'},'white.propname',{token: 'identifier.$1.propname'},{token: 'white.params',next: '@var_decl.param'}]],
			[/(def|set|get)(\s)(@propertyPath)(\()/,[{token: 'keyword.$1'},'white.propname',{token: 'identifier.$1.propname'},{token: 'params.param.open',next: '@var_parens.param'}]],
			[/(def|set|get)(\s)(@propertyPath)/,[{token: 'keyword.$1'},'white.propname',{token: 'identifier.$1.propname'}]]
		],
		
		class_statement: [
			[/(class)(\s)(@identifier)/,[{token: 'keyword.$1'},'white.classname',{token: 'identifier.$1.name'}]]
		],
		tag_statement: [
			[/(tag)(\s)(@tagNameIdentifier)(\s)(\<)(\s)(@tagNameIdentifier)/,['keyword.tag','white.tagname','identifier.tagname','white','operator.extends','white','identifier.tagname']],
			[/(tag)(\s)(@tagNameIdentifier)(\s)(?=\{|\w|\[)/,[{token: 'keyword.$1'},'white.classname',{token: 'identifier.$1.name'}]]
		],
		
		import_body: [
			eolpop,
			[/(\*)(\s+)(as)(\s+)(@esmIdentifier)/,['keyword.star','white','keyword.as','white','variable.imports']],
			[/(@esmIdentifier)(\s+)(as)(\s+)(@esmIdentifier)/,['alias','white','keyword.as','white','variable.imports']],
			[/from/,'keyword.from'],
			[/\{/,'imports.open','@esm_specifiers.imports'],
			[/(@esmIdentifier)/,'variable.imports'],
			{include: 'string_start'}
		],
		
		esm_specifiers: [
			[/\}/,'$S2.close','@pop'],
			[/(@esmIdentifier)(\s+)(as)(\s+)(@esmIdentifier)/,['alias','white','keyword.as','white',{token: 'variable.$S2'}]],
			[/(@esmIdentifier)/,{token: 'variable.$S2'}],
			[/\,/,'delimiter']
		],
		
		import_statement: [
			[/(import)/,'keyword.import','@import_body.start']
		],
		
		object: [
			[/\{/,'delimiter.bracket.open','@object'],
			[/\}/,'delimiter.bracket.close','@pop'],
			[/(@identifier)/,'identifier.key'],
			{include: 'common'},
			{include: 'string_start'},
			{include: 'comments'},
			[/:/,'delimiter.object.value','@object_value'],
			[/\,/,'delimiter']
		],
		
		object_start: [
			[/\{/,'delimiter.bracket.open','@object']
		],
		
		array_start: [
			[/\[/,'array.open','@array']
		],
		
		array: [
			[/\]/,'array.close','@pop'],
			[/\,/,'delimiter'],
			{include: 'expression'}
		],
		
		expressions: [
			[/\,/,'delimiter'],
			{include: 'expression'}
		
		],
		
		var_object: [
			[/\{/,'object.open','@var_object'],
			[/\}/,'object.close','@pop'],
			[/(@identifier)/,{token: 'variable.$S2'}],
			{include: 'common'},
			[/\,/,'delimiter']
		],
		
		var_array: [
			[/\{/,'object.open','@var_object'],
			[/\}/,'object.close','@pop'],
			[/\[/,'array.open','@var_array'],
			[/\]/,'array.close','@pop'],
			[/(@identifier)/,{token: 'variable.$S2'}],
			{include: 'common'},
			[/\,/,'delimiter']
		],
		
		object_value: [
			eolpop,
			[/(?=,|\})/,'delimiter','@pop'],
			{include: 'expression'}
		],
		
		var_value: [
			eolpop,
			[/(?=,|@newline|\))/,'delimiter','@pop'],
			{include: 'expression'}
		],
		
		var_decl: [
			eolpop,
			[/(@variable)/,{token: 'variable.$S2'}],
			[/\s*(=)\s*/,'operator','@var_value'],
			[/\{/,'object.open','@var_object.$S2'],
			[/\[/,'array.open','@var_array.$S2'],
			[/,/,'delimiter'],
			[/(,)(@newline)/,['delimiter','newline']],
			[/@newline/,{token: '@rematch',next: '@pop'}],
			[/(?=\n)/,'delimiter','@pop'],
			{include: 'spread'},
			{include: 'common'},
			{include: 'type_start'},
			{include: 'comments'}
		],
		
		var_params: [
			{include: 'var_decl'}
		],
		
		single_var_decl: [
			[/(?=[,\)\]\n]|@newline)/,'delimiter','@pop'],
			{include: 'var_decl'}
		],
		
		forin_var_decl: [
			[/\s(in|of)/,'keyword','@pop'],
			{include: 'var_decl'}
		],
		
		body: [
			{include: 'statements'},
			[/@newline/,'newline'],
			[/(class|tag)(?=\s)/,{token: 'keyword.$1',next: '@declstart.$1'}],
			[/(def|get|set)(?=\s)/,{token: 'keyword.$1',next: '@defstart.$1'}],
			[/(prop|attr)(?=\s)/,{token: 'keyword.$1',next: '@propstart.$1'}],
			
			[/([a-z]\w*)(:?(?!\w))/,{
				cases: {
					$2: ['key.identifier','delimiter'],
					this: 'this',
					self: 'self',
					'$1@boolean': {token: 'boolean.$0'},
					'$1@keywords': {token: 'keyword.$0'},
					'$1@contextual_keywords': {token: 'identifier.$0'},
					'@default': ['identifier','delimiter']
				}
			}],
			[/\$\w+\$/,'identifier.env'],
			[/\$\d+/,'identifier.special'],
			[/\$[a-zA-Z_]\w*/,'identifier.sys'],
			[/[A-Z][A-Za-z\d\-\_]*/,{token: 'identifier.const'}],
			[/[a-z_][A-Za-z\d\-\_]*/,{token: 'identifier'}],
			
			
			[/\(/,{token: 'paren.open',next: '@parens'}],
			
			// whitespace
			{include: '@whitespace'},
			{include: '@comments'},
			
			[/(\:)([\@\w\-\_]+)/,['symbol.start','symbol']],
			[/\$\d+/,'entity.special.arg'],
			
			// regular expressions
			[/\/(?!\ )(?=([^\\\/]|\\.)+\/)/,{token: 'regexp.slash',bracket: '@open',next: '@regexp'}],
			
			// should drop this
			[/}/,{cases: {
				'$S2==interpolatedstring': {token: 'string.bracket.close',next: '@pop'},
				'@default': '@brackets'
			}}],
			[/[\{\}\(\)\[\]]/,'@brackets'],
			
			{include: '@operators'},
			
			// numbers
			{include: '@number'},
			// delimiter: after number because of .\d floats
			[/\,/,'delimiter.comma'],
			[/\./,'delimiter.dot']
		],
		js_comment: [
			[/###/,{token: 'comment',next: '@pop',nextEmbedded: '@pop'}]
		],
		
		string_start: [
			[/"""/,'string','@herestring."""'],
			[/'''/,'string','@herestring.\'\'\''],
			[/"/,{token: 'string.open',next: '@string."'}],
			[/'/,{token: 'string.open',next: '@string.\''}],
			[/\`/,{token: 'string.open',next: '@string.\`'}]
		],
		number: [
			[/\d+[eE]([\-+]?\d+)?/,'number.float'],
			[/\d+\.\d+([eE][\-+]?\d+)?/,'number.float'],
			[/0[xX][0-9a-fA-F]+/,'number.hex'],
			[/0[0-7]+(?!\d)/,'number.octal'],
			[/\d+/,'number']
		],
		operators: [
			{include: 'spread'},
			[/,/,'delimiter'],
			[/@symbols/,{cases: {
				'@operators': 'operator',
				'@math': 'operator.math',
				'@logic': 'operator.logic',
				'@dot': 'operator.dot',
				'@default': 'delimiter'
			}}],
			
			[/\&\b/,'operator']
		],
		whitespace: [
			[/[ \t\r\n]+/,'white']
		],
		
		comments: [
			[/###\s(css)/,{token: 'style.$1.open'},'@style.$1'],
			[/###/,{token: 'comment.block.open'},'@comment.block'],
			[/#(\s.+)?$/,'comment'],
			[/\/\/(.+)$/,'comment']
		],
		
		comment: [
			[/[^#]+/,'comment'],
			[/###/,{token: 'comment.$S2.close'},'@pop'],
			[/#/,'comment']
		],
		
		style: [
			[/###/,{token: 'style.$S2.close'},'@pop']
		],
		
		tag_start: [
			[/(<)(?=\.)/,'tag.open','@tag.flag'],
			[/(<)(?=\w|\{|>)/,'tag.open','@tag.name']
		],
		
		tag: [
			[/>/,'tag.close','@pop'],
			[/(\-?@tagIdentifier)/,{token: 'tag.$S2'}],
			[/(\-?\d+)/,{token: 'tag.$S2'}],
			[/\./,{cases: {
				'$S2==event': {token: 'tag.modifier.start',switchTo: 'tag.modifier'},
				'$S2==modifier': {token: 'tag.modifier.start',switchTo: 'tag.modifier'},
				'@default': {token: 'tag.flag.start',switchTo: 'tag.flag'}
			}}],
			
			[/(\s*\=\s*)/,{token: 'tag.operator.equals',next: 'tag_value'}],
			[/\:/,{token: 'tag.event.start',switchTo: 'tag.event'}],
			[/\{/,{token: 'tag.$S2.braces.open',next: '@tag_interpolation.$S2'}],
			[/\[/,{token: 'tag.data.open',next: '@tag_data'}],
			[/\s+/,{token: 'white',switchTo: 'tag.attr'}],
			[/\@(@tagIdentifier)/,{token: 'tag.reference'}]
		],
		
		tag_interpolation: [
			[/\}/,{token: 'tag.$S2.braces.close',next: '@pop'}],
			{include: 'expression'},
			[/\)|\]/,{token: 'invalid'}]
		],
		
		tag_data: [
			[/\]/,{token: 'tag.data.close',next: '@pop'}],
			{include: 'expression'},
			[/\)|\]|\}/,{token: 'invalid'}]
		],
		
		tag_singleton_ref: [
			[/\#(-*[a-zA-Z][\w\-]*)+/,'tag.singleton.ref']
		],
		tag_value: [
			[/(?=(\:?[\w]+\=))/,{token: '',next: '@pop'}],
			[/(?=(\>|\s))/,{token: '',next: '@pop'}],
			{include: 'expression'}
		],
		tag_parens: [
			[/\)/,{token: 'paren.close.tag',next: '@pop'}],
			[/(\))(\:?)/,['paren.close.tag','delimiter.colon'],'@pop'],
			{include: 'body'}
		],
		
		braces: [
			['}',{token: 'brace.close',next: '@pop'}],
			{include: 'body'}
		],
		brackets: [
			[']',{token: 'bracket.close',next: '@pop'}],
			{include: 'body'}
		],
		
		declstart: [
			[/^./,{token: '@rematch',next: '@pop'}],
			[/[A-Z][A-Za-z\d\-\_]*/,{token: 'identifier.decl.$S2'}],
			[/\./,{token: 'delimiter.dot'}],
			[/[a-z_][A-Za-z\d\-\_]*/,{token: 'identifier.decl.$S2'}],
			[/[ \t\<\>]+/,'operator.inherits string']
		],
		
		defstart: [
			[/(self)\./,{token: 'identifier.decl.def.self'}],
			[/@methodName/,{token: 'identifier.decl.def',next: '@pop'}],
			[/^./,{token: '@rematch',next: '@pop'}]
		],
		
		propstart: [
			[/@identifier/,{token: 'identifier.decl.$S2',next: '@pop'}],
			[/^./,{token: '@rematch',next: '@pop'}]
		],
		
		string: [
			[/[^"'\`\{\\]+/,'string'],
			[/@escapes/,'string.escape'],
			[/\./,'string.escape.invalid'],
			[/\./,'string.escape.invalid'],
			[/\{/,{cases: {
				'$S2=="': {token: 'string.bracket.open',next: 'root.interpolatedstring'},
				'@default': 'string'
			}}],
			[/["'`]/,{cases: {'$#==$S2': {token: 'string.close',next: '@pop'},'@default': 'string'}}],
			[/#/,'string']
		],
		herestring: [
			[/("""|''')/,{cases: {'$1==$S2': {token: 'string',next: '@pop'},'@default': 'string'}}],
			[/[^#\\'"\{]+/,'string'],
			[/['"]+/,'string'],
			[/@escapes/,'string.escape'],
			[/\./,'string.escape.invalid'],
			[/\{/,{cases: {'$S2=="""': {token: 'string',next: 'root.interpolatedstring'},'@default': 'string'}}],
			[/#/,'string']
		],
		
		hereregexp: [
			[/[^\\\/#]/,'regexp'],
			[/\\./,'regexp'],
			[/#.*$/,'comment'],
			['///[igm]*',{token: 'regexp',next: '@pop'}],
			[/\//,'regexp']
		],
		
		regexp_start: [
			[/\/(?!\ )(?=([^\\\/]|\\.)+\/)/,{token: 'regexp.slash.open',bracket: '@open',next: '@regexp'}]
		],
		
		regexp: [
			[/(\{)(\d+(?:,\d*)?)(\})/,['regexp.escape.control','regexp.escape.control','regexp.escape.control']],
			[/(\[)(\^?)(?=(?:[^\]\\\/]|\\.)+)/,['regexp.escape.control',{token: 'regexp.escape.control',next: '@regexrange'}]],
			[/(\()(\?:|\?=|\?!)/,['regexp.escape.control','regexp.escape.control']],
			[/[()]/,'regexp.escape.control'],
			[/@regexpctl/,'regexp.escape.control'],
			[/[^\\\/]/,'regexp'],
			[/@regexpesc/,'regexp.escape'],
			[/\\:/,'regexp.escape'],
			[/\\\./,'regexp.invalid'],
			[/(\/)(\w*)/,[{token: 'regexp.slash.close',bracket: '@close'},{token: 'regexp.flags',next: '@pop'}]],
			['/',{token: 'regexp.slash.close',bracket: '@close'},'@pop'],
			[/./,'regexp.invalid']
		],
		
		regexrange: [
			[/-/,'regexp.escape.control'],
			[/\^/,'regexp.invalid'],
			[/@regexpesc/,'regexp.escape'],
			[/[^\]]/,'regexp'],
			[/\]/,'regexp.escape.control','@pop']
		]
	}
};

function isFuzzyActionArr(what) {
    return (Array.isArray(what));
}
function isFuzzyAction(what) {
    return !isFuzzyActionArr(what);
}
function isString(what) {
    return (typeof what === 'string');
}
function isIAction(what) {
    return !isString(what);
}
function empty(s) {
    return (s ? false : true);
}
function fixCase(lexer, str) {
    return (lexer.ignoreCase && str ? str.toLowerCase() : str);
}
function sanitize(s) {
    return s.replace(/[&<>'"_]/g, '-');
}
function log(lexer, msg) {
    console.log(lexer.languageId + ": " + msg);
}
function createError(lexer, msg) {
    return new Error(lexer.languageId + ": " + msg);
}
function substituteMatches(lexer, str, id, matches, state) {
    var re = /\$((\$)|(#)|(\d\d?)|[sS](\d\d?)|@(\w+))/g;
    var stateMatches = null;
    return str.replace(re, function (full, sub, dollar, hash, n, s, attr, ofs, total) {
        if (!empty(dollar)) {
            return '$';
        }
        if (!empty(hash)) {
            return fixCase(lexer, id);
        }
        if (!empty(n) && n < matches.length) {
            return fixCase(lexer, matches[n]);
        }
        if (!empty(attr) && lexer && typeof (lexer[attr]) === 'string') {
            return lexer[attr];
        }
        if (stateMatches === null) {
            stateMatches = state.split('.');
            stateMatches.unshift(state);
        }
        if (!empty(s) && s < stateMatches.length) {
            return fixCase(lexer, stateMatches[s]);
        }
        return '';
    });
}
function findRules(lexer, inState) {
    var state = inState;
    while (state && state.length > 0) {
        var rules = lexer.tokenizer[state];
        if (rules) {
            return rules;
        }
        var idx = state.lastIndexOf('.');
        if (idx < 0) {
            state = null;
        }
        else {
            state = state.substr(0, idx);
        }
    }
    return null;
}
function stateExists(lexer, inState) {
    var state = inState;
    while (state && state.length > 0) {
        var exist = lexer.stateNames[state];
        if (exist) {
            return true;
        }
        var idx = state.lastIndexOf('.');
        if (idx < 0) {
            state = null;
        }
        else {
            state = state.substr(0, idx);
        }
    }
    return false;
}

function isArrayOf(elemType, obj) {
    if (!obj) {
        return false;
    }
    if (!(Array.isArray(obj))) {
        return false;
    }
    for (var _i = 0, obj_1 = obj; _i < obj_1.length; _i++) {
        var el = obj_1[_i];
        if (!(elemType(el))) {
            return false;
        }
    }
    return true;
}
function bool(prop, defValue) {
    if (typeof prop === 'boolean') {
        return prop;
    }
    return defValue;
}
function string(prop, defValue) {
    if (typeof (prop) === 'string') {
        return prop;
    }
    return defValue;
}
function arrayToHash(array) {
    var result = {};
    for (var _i = 0, array_1 = array; _i < array_1.length; _i++) {
        var e = array_1[_i];
        result[e] = true;
    }
    return result;
}
function createKeywordMatcher(arr, caseInsensitive) {
    if (caseInsensitive === void 0) { caseInsensitive = false; }
    if (caseInsensitive) {
        arr = arr.map(function (x) { return x.toLowerCase(); });
    }
    var hash = arrayToHash(arr);
    if (caseInsensitive) {
        return function (word) {
            return hash[word.toLowerCase()] !== undefined && hash.hasOwnProperty(word.toLowerCase());
        };
    }
    else {
        return function (word) {
            return hash[word] !== undefined && hash.hasOwnProperty(word);
        };
    }
}
function compileRegExp(lexer, str) {
    var n = 0;
    while (str.indexOf('@') >= 0 && n < 5) {
        n++;
        str = str.replace(/@(\w+)/g, function (s, attr) {
            var sub = '';
            if (typeof (lexer[attr]) === 'string') {
                sub = lexer[attr];
            }
            else if (lexer[attr] && lexer[attr] instanceof RegExp) {
                sub = lexer[attr].source;
            }
            else {
                if (lexer[attr] === undefined) {
                    throw createError(lexer, 'language definition does not contain attribute \'' + attr + '\', used at: ' + str);
                }
                else {
                    throw createError(lexer, 'attribute reference \'' + attr + '\' must be a string, used at: ' + str);
                }
            }
            return (empty(sub) ? '' : '(?:' + sub + ')');
        });
    }
    return new RegExp(str, (lexer.ignoreCase ? 'i' : ''));
}
function selectScrutinee(id, matches, state, num) {
    if (num < 0) {
        return id;
    }
    if (num < matches.length) {
        return matches[num];
    }
    if (num >= 100) {
        num = num - 100;
        var parts = state.split('.');
        parts.unshift(state);
        if (num < parts.length) {
            return parts[num];
        }
    }
    return null;
}
function createGuard(lexer, ruleName, tkey, val) {
    var scrut = -1;
    var oppat = tkey;
    var matches = tkey.match(/^\$(([sS]?)(\d\d?)|#)(.*)$/);
    if (matches) {
        if (matches[3]) {
            scrut = parseInt(matches[3]);
            if (matches[2]) {
                scrut = scrut + 100;
            }
        }
        oppat = matches[4];
    }
    var op = '~';
    var pat = oppat;
    if (!oppat || oppat.length === 0) {
        op = '!=';
        pat = '';
    }
    else if (/^\w*$/.test(pat)) {
        op = '==';
    }
    else {
        matches = oppat.match(/^(@|!@|~|!~|==|!=)(.*)$/);
        if (matches) {
            op = matches[1];
            pat = matches[2];
        }
    }
    var tester;
    if ((op === '~' || op === '!~') && /^(\w|\|)*$/.test(pat)) {
        var inWords_1 = createKeywordMatcher(pat.split('|'), lexer.ignoreCase);
        tester = function (s) { return (op === '~' ? inWords_1(s) : !inWords_1(s)); };
    }
    else if (op === '@' || op === '!@') {
        var words = lexer[pat];
        if (!words) {
            throw createError(lexer, 'the @ match target \'' + pat + '\' is not defined, in rule: ' + ruleName);
        }
        if (!(isArrayOf(function (elem) { return (typeof (elem) === 'string'); }, words))) {
            throw createError(lexer, 'the @ match target \'' + pat + '\' must be an array of strings, in rule: ' + ruleName);
        }
        var inWords_2 = createKeywordMatcher(words, lexer.ignoreCase);
        tester = function (s) { return (op === '@' ? inWords_2(s) : !inWords_2(s)); };
    }
    else if (op === '~' || op === '!~') {
        if (pat.indexOf('$') < 0) {
            var re_1 = compileRegExp(lexer, '^' + pat + '$');
            tester = function (s) { return (op === '~' ? re_1.test(s) : !re_1.test(s)); };
        }
        else {
            tester = function (s, id, matches, state) {
                var re = compileRegExp(lexer, '^' + substituteMatches(lexer, pat, id, matches, state) + '$');
                return re.test(s);
            };
        }
    }
    else {
        if (pat.indexOf('$') < 0) {
            var patx_1 = fixCase(lexer, pat);
            tester = function (s) { return (op === '==' ? s === patx_1 : s !== patx_1); };
        }
        else {
            var patx_2 = fixCase(lexer, pat);
            tester = function (s, id, matches, state, eos) {
                var patexp = substituteMatches(lexer, patx_2, id, matches, state);
                return (op === '==' ? s === patexp : s !== patexp);
            };
        }
    }
    if (scrut === -1) {
        return {
            name: tkey, value: val, test: function (id, matches, state, eos) {
                return tester(id, id, matches, state, eos);
            }
        };
    }
    else {
        return {
            name: tkey, value: val, test: function (id, matches, state, eos) {
                var scrutinee = selectScrutinee(id, matches, state, scrut);
                return tester(!scrutinee ? '' : scrutinee, id, matches, state, eos);
            }
        };
    }
}
function compileAction(lexer, ruleName, action) {
    if (!action) {
        return { token: '' };
    }
    else if (typeof (action) === 'string') {
        return action;
    }
    else if (action.token || action.token === '') {
        if (typeof (action.token) !== 'string') {
            throw createError(lexer, 'a \'token\' attribute must be of type string, in rule: ' + ruleName);
        }
        else {
            var newAction = { token: action.token };
            if (action.token.indexOf('$') >= 0) {
                newAction.tokenSubst = true;
            }
            if (typeof (action.bracket) === 'string') {
                if (action.bracket === '@open') {
                    newAction.bracket = 1;
                }
                else if (action.bracket === '@close') {
                    newAction.bracket = -1;
                }
                else {
                    throw createError(lexer, 'a \'bracket\' attribute must be either \'@open\' or \'@close\', in rule: ' + ruleName);
                }
            }
            if (action.next) {
                if (typeof (action.next) !== 'string') {
                    throw createError(lexer, 'the next state must be a string value in rule: ' + ruleName);
                }
                else {
                    var next = action.next;
                    if (!/^(@pop|@push|@popall)$/.test(next)) {
                        if (next[0] === '@') {
                            next = next.substr(1);
                        }
                        if (next.indexOf('$') < 0) {
                            if (!stateExists(lexer, substituteMatches(lexer, next, '', [], ''))) {
                                throw createError(lexer, 'the next state \'' + action.next + '\' is not defined in rule: ' + ruleName);
                            }
                        }
                    }
                    newAction.next = next;
                }
            }
            if (typeof (action.goBack) === 'number') {
                newAction.goBack = action.goBack;
            }
            if (typeof (action.switchTo) === 'string') {
                newAction.switchTo = action.switchTo;
            }
            if (typeof (action.log) === 'string') {
                newAction.log = action.log;
            }
            if (typeof (action.nextEmbedded) === 'string') {
                newAction.nextEmbedded = action.nextEmbedded;
                lexer.usesEmbedded = true;
            }
            return newAction;
        }
    }
    else if (Array.isArray(action)) {
        var results = [];
        for (var i = 0, len = action.length; i < len; i++) {
            results[i] = compileAction(lexer, ruleName, action[i]);
        }
        return { group: results };
    }
    else if (action.cases) {
        var cases_1 = [];
        for (var tkey in action.cases) {
            if (action.cases.hasOwnProperty(tkey)) {
                var val = compileAction(lexer, ruleName, action.cases[tkey]);
                if (tkey === '@default' || tkey === '@' || tkey === '') {
                    cases_1.push({ test: undefined, value: val, name: tkey });
                }
                else if (tkey === '@eos') {
                    cases_1.push({ test: function (id, matches, state, eos) { return eos; }, value: val, name: tkey });
                }
                else {
                    cases_1.push(createGuard(lexer, ruleName, tkey, val));
                }
            }
        }
        var def_1 = lexer.defaultToken;
        return {
            test: function (id, matches, state, eos) {
                for (var _i = 0, cases_2 = cases_1; _i < cases_2.length; _i++) {
                    var _case = cases_2[_i];
                    var didmatch = (!_case.test || _case.test(id, matches, state, eos));
                    if (didmatch) {
                        return _case.value;
                    }
                }
                return def_1;
            }
        };
    }
    else {
        throw createError(lexer, 'an action must be a string, an object with a \'token\' or \'cases\' attribute, or an array of actions; in rule: ' + ruleName);
    }
}
var Rule = (function () {
    function Rule(name) {
        this.regex = new RegExp('');
        this.action = { token: '' };
        this.matchOnlyAtLineStart = false;
        this.name = '';
        this.name = name;
    }
    Rule.prototype.setRegex = function (lexer, re) {
        var sregex;
        if (typeof (re) === 'string') {
            sregex = re;
        }
        else if (re instanceof RegExp) {
            sregex = re.source;
        }
        else {
            throw createError(lexer, 'rules must start with a match string or regular expression: ' + this.name);
        }
        this.matchOnlyAtLineStart = (sregex.length > 0 && sregex[0] === '^');
        this.name = this.name + ': ' + sregex;
        this.regex = compileRegExp(lexer, '^(?:' + (this.matchOnlyAtLineStart ? sregex.substr(1) : sregex) + ')');
    };
    Rule.prototype.setAction = function (lexer, act) {
        this.action = compileAction(lexer, this.name, act);
    };
    return Rule;
}());
function compile(languageId, json) {
    if (!json || typeof (json) !== 'object') {
        throw new Error('Monarch: expecting a language definition object');
    }
    var lexer = {};
    lexer.languageId = languageId;
    lexer.noThrow = false;
    lexer.maxStack = 100;
    lexer.start = (typeof json.start === 'string' ? json.start : null);
    lexer.ignoreCase = bool(json.ignoreCase, false);
    lexer.tokenPostfix = string(json.tokenPostfix, '.' + lexer.languageId);
    lexer.defaultToken = string(json.defaultToken, 'source');
    lexer.usesEmbedded = false;
    var lexerMin = json;
    lexerMin.languageId = languageId;
    lexerMin.ignoreCase = lexer.ignoreCase;
    lexerMin.noThrow = lexer.noThrow;
    lexerMin.usesEmbedded = lexer.usesEmbedded;
    lexerMin.stateNames = json.tokenizer;
    lexerMin.defaultToken = lexer.defaultToken;
    function addRules(state, newrules, rules) {
        for (var _i = 0, rules_1 = rules; _i < rules_1.length; _i++) {
            var rule = rules_1[_i];
            var include = rule.include;
            if (include) {
                if (typeof (include) !== 'string') {
                    throw createError(lexer, 'an \'include\' attribute must be a string at: ' + state);
                }
                if (include[0] === '@') {
                    include = include.substr(1);
                }
                if (!json.tokenizer[include]) {
                    throw createError(lexer, 'include target \'' + include + '\' is not defined at: ' + state);
                }
                addRules(state + '.' + include, newrules, json.tokenizer[include]);
            }
            else {
                var newrule = new Rule(state);
                if (Array.isArray(rule) && rule.length >= 1 && rule.length <= 3) {
                    newrule.setRegex(lexerMin, rule[0]);
                    if (rule.length >= 3) {
                        if (typeof (rule[1]) === 'string') {
                            newrule.setAction(lexerMin, { token: rule[1], next: rule[2] });
                        }
                        else if (typeof (rule[1]) === 'object') {
                            var rule1 = rule[1];
                            rule1.next = rule[2];
                            newrule.setAction(lexerMin, rule1);
                        }
                        else {
                            throw createError(lexer, 'a next state as the last element of a rule can only be given if the action is either an object or a string, at: ' + state);
                        }
                    }
                    else {
                        newrule.setAction(lexerMin, rule[1]);
                    }
                }
                else {
                    if (!rule.regex) {
                        throw createError(lexer, 'a rule must either be an array, or an object with a \'regex\' or \'include\' field at: ' + state);
                    }
                    if (rule.name) {
                        if (typeof rule.name === 'string') {
                            newrule.name = rule.name;
                        }
                    }
                    if (rule.matchOnlyAtStart) {
                        newrule.matchOnlyAtLineStart = bool(rule.matchOnlyAtLineStart, false);
                    }
                    newrule.setRegex(lexerMin, rule.regex);
                    newrule.setAction(lexerMin, rule.action);
                }
                newrules.push(newrule);
            }
        }
    }
    if (!json.tokenizer || typeof (json.tokenizer) !== 'object') {
        throw createError(lexer, 'a language definition must define the \'tokenizer\' attribute as an object');
    }
    lexer.tokenizer = [];
    for (var key in json.tokenizer) {
        if (json.tokenizer.hasOwnProperty(key)) {
            if (!lexer.start) {
                lexer.start = key;
            }
            var rules = json.tokenizer[key];
            lexer.tokenizer[key] = new Array();
            addRules('tokenizer.' + key, lexer.tokenizer[key], rules);
        }
    }
    lexer.usesEmbedded = lexerMin.usesEmbedded;
    if (json.brackets) {
        if (!(Array.isArray(json.brackets))) {
            throw createError(lexer, 'the \'brackets\' attribute must be defined as an array');
        }
    }
    else {
        json.brackets = [
            { open: '{', close: '}', token: 'delimiter.curly' },
            { open: '[', close: ']', token: 'delimiter.square' },
            { open: '(', close: ')', token: 'delimiter.parenthesis' },
            { open: '<', close: '>', token: 'delimiter.angle' }
        ];
    }
    var brackets = [];
    for (var _i = 0, _a = json.brackets; _i < _a.length; _i++) {
        var el = _a[_i];
        var desc = el;
        if (desc && Array.isArray(desc) && desc.length === 3) {
            desc = { token: desc[2], open: desc[0], close: desc[1] };
        }
        if (desc.open === desc.close) {
            throw createError(lexer, 'open and close brackets in a \'brackets\' attribute must be different: ' + desc.open +
                '\n hint: use the \'bracket\' attribute if matching on equal brackets is required.');
        }
        if (typeof desc.open === 'string' && typeof desc.token === 'string' && typeof desc.close === 'string') {
            brackets.push({
                token: desc.token + lexer.tokenPostfix,
                open: fixCase(lexer, desc.open),
                close: fixCase(lexer, desc.close)
            });
        }
        else {
            throw createError(lexer, 'every element in the \'brackets\' array must be a \'{open,close,token}\' object or array');
        }
    }
    lexer.brackets = brackets;
    lexer.noThrow = true;
    return lexer;
}

var Token = (function () {
    function Token(offset, type, language) {
        this.offset = offset | 0;
        this.type = type;
        this.language = language;
        this.value = null;
        this.whitespace = null;
        this.stack = null;
    }
    Token.prototype.toString = function () {
        return '(' + this.offset + ', ' + this.type + ')';
    };
    Token.prototype.match = function (val) {
        if (typeof val == 'string') {
            if (val.indexOf(' ') > 0) {
                val = val.split(' ');
            }
            else if (this.type.indexOf(val) >= 0) {
                return true;
            }
        }
        if (val instanceof Array) {
            for (var _i = 0, val_1 = val; _i < val_1.length; _i++) {
                var item = val_1[_i];
                if (this.type.indexOf(item) >= 0) {
                    return true;
                }
            }
        }
        if (val instanceof RegExp) {
            return val.test(this.type);
        }
        return false;
    };
    return Token;
}());
var TokenizationResult = (function () {
    function TokenizationResult(tokens, endState) {
        this.tokens = tokens;
        this.endState = endState;
    }
    return TokenizationResult;
}());

var CACHE_STACK_DEPTH = 5;
var MonarchStackElementFactory = (function () {
    function MonarchStackElementFactory(maxCacheDepth) {
        this._maxCacheDepth = maxCacheDepth;
        this._entries = Object.create(null);
    }
    MonarchStackElementFactory.create = function (parent, state) {
        return this._INSTANCE.create(parent, state);
    };
    MonarchStackElementFactory.prototype.create = function (parent, state) {
        if (parent !== null && parent.depth >= this._maxCacheDepth) {
            return new MonarchStackElement(parent, state);
        }
        var stackElementId = MonarchStackElement.getStackElementId(parent);
        if (stackElementId.length > 0) {
            stackElementId += '|';
        }
        stackElementId += state;
        var result = this._entries[stackElementId];
        if (result) {
            return result;
        }
        result = new MonarchStackElement(parent, state);
        this._entries[stackElementId] = result;
        return result;
    };
    MonarchStackElementFactory._INSTANCE = new MonarchStackElementFactory(CACHE_STACK_DEPTH);
    return MonarchStackElementFactory;
}());
var MonarchStackElement = (function () {
    function MonarchStackElement(parent, state) {
        this.parent = parent;
        this.state = state;
        this.depth = (this.parent ? this.parent.depth : 0) + 1;
    }
    MonarchStackElement.getStackElementId = function (element) {
        var result = '';
        while (element !== null) {
            if (result.length > 0) {
                result += '|';
            }
            result += element.state;
            element = element.parent;
        }
        return result;
    };
    MonarchStackElement._equals = function (a, b) {
        while (a !== null && b !== null) {
            if (a === b) {
                return true;
            }
            if (a.state !== b.state) {
                return false;
            }
            a = a.parent;
            b = b.parent;
        }
        if (a === null && b === null) {
            return true;
        }
        return false;
    };
    MonarchStackElement.prototype.equals = function (other) {
        return MonarchStackElement._equals(this, other);
    };
    MonarchStackElement.prototype.push = function (state) {
        return MonarchStackElementFactory.create(this, state);
    };
    MonarchStackElement.prototype.pop = function () {
        return this.parent;
    };
    MonarchStackElement.prototype.popall = function () {
        var result = this;
        while (result.parent) {
            result = result.parent;
        }
        return result;
    };
    MonarchStackElement.prototype.switchTo = function (state) {
        return MonarchStackElementFactory.create(this.parent, state);
    };
    return MonarchStackElement;
}());
var MonarchLineStateFactory = (function () {
    function MonarchLineStateFactory(maxCacheDepth) {
        this._maxCacheDepth = maxCacheDepth;
        this._entries = Object.create(null);
    }
    MonarchLineStateFactory.create = function (stack) {
        return this._INSTANCE.create(stack);
    };
    MonarchLineStateFactory.prototype.create = function (stack) {
        if (stack !== null && stack.depth >= this._maxCacheDepth) {
            return new MonarchLineState(stack);
        }
        var stackElementId = MonarchStackElement.getStackElementId(stack);
        var result = this._entries[stackElementId];
        if (result) {
            return result;
        }
        result = new MonarchLineState(stack);
        this._entries[stackElementId] = result;
        return result;
    };
    MonarchLineStateFactory._INSTANCE = new MonarchLineStateFactory(CACHE_STACK_DEPTH);
    return MonarchLineStateFactory;
}());
var MonarchLineState = (function () {
    function MonarchLineState(stack) {
        this.stack = stack;
    }
    MonarchLineState.prototype.clone = function () {
        return MonarchLineStateFactory.create(this.stack);
    };
    MonarchLineState.prototype.equals = function (other) {
        if (!(other instanceof MonarchLineState)) {
            return false;
        }
        if (!this.stack.equals(other.stack)) {
            return false;
        }
        return true;
    };
    return MonarchLineState;
}());
var MonarchClassicTokensCollector = (function () {
    function MonarchClassicTokensCollector() {
        this._tokens = [];
        this._language = null;
        this._lastToken = new Token(0, 'start', 'imba');
        this._lastTokenType = null;
    }
    MonarchClassicTokensCollector.prototype.enterMode = function (startOffset, modeId) {
        this._language = modeId;
    };
    MonarchClassicTokensCollector.prototype.emit = function (startOffset, type, stack) {
        if (this._lastTokenType === type && !this._lastToken.whitespace) {
            return this._lastToken;
        }
        var token = new Token(startOffset, type, this._language);
        this._lastTokenType = type;
        this._lastToken = token;
        this._tokens.push(token);
        return token;
    };
    MonarchClassicTokensCollector.prototype.finalize = function (endState) {
        return new TokenizationResult(this._tokens, endState);
    };
    return MonarchClassicTokensCollector;
}());
var MonarchTokenizer = (function () {
    function MonarchTokenizer(modeId, lexer) {
        this._modeId = modeId;
        this._lexer = lexer;
    }
    MonarchTokenizer.prototype.dispose = function () {
    };
    MonarchTokenizer.prototype.getLoadStatus = function () {
        return { loaded: true };
    };
    MonarchTokenizer.prototype.getInitialState = function () {
        var rootState = MonarchStackElementFactory.create(null, this._lexer.start);
        return MonarchLineStateFactory.create(rootState);
    };
    MonarchTokenizer.prototype.tokenize = function (line, lineState, offsetDelta) {
        var tokensCollector = new MonarchClassicTokensCollector();
        var endLineState = this._tokenize(line, lineState, offsetDelta, tokensCollector);
        return tokensCollector.finalize(endLineState);
    };
    MonarchTokenizer.prototype._tokenize = function (line, lineState, offsetDelta, collector) {
        return this._myTokenize(line, lineState, offsetDelta, collector);
    };
    MonarchTokenizer.prototype._safeRuleName = function (rule) {
        if (rule) {
            return rule.name;
        }
        return '(unknown)';
    };
    MonarchTokenizer.prototype._myTokenize = function (line, lineState, offsetDelta, tokensCollector) {
        tokensCollector.enterMode(offsetDelta, this._modeId);
        var lineLength = line.length;
        var stack = lineState.stack;
        var lastToken = null;
        var pos = 0;
        var groupMatching = null;
        var forceEvaluation = true;
        while (forceEvaluation || pos < lineLength) {
            var pos0 = pos;
            var stackLen0 = stack.depth;
            var groupLen0 = groupMatching ? groupMatching.groups.length : 0;
            var state = stack.state;
            var matches = null;
            var matched = null;
            var action = null;
            var rule = null;
            if (groupMatching) {
                matches = groupMatching.matches;
                var groupEntry = groupMatching.groups.shift();
                matched = groupEntry.matched;
                action = groupEntry.action;
                rule = groupMatching.rule;
                if (groupMatching.groups.length === 0) {
                    groupMatching = null;
                }
            }
            else {
                if (!forceEvaluation && pos >= lineLength) {
                    break;
                }
                forceEvaluation = false;
                var rules = this._lexer.tokenizer[state];
                if (!rules) {
                    rules = findRules(this._lexer, state);
                    if (!rules) {
                        throw createError(this._lexer, 'tokenizer state is not defined: ' + state);
                    }
                }
                var restOfLine = line.substr(pos);
                for (var _i = 0, rules_1 = rules; _i < rules_1.length; _i++) {
                    var rule_1 = rules_1[_i];
                    if (pos === 0 || !rule_1.matchOnlyAtLineStart) {
                        matches = restOfLine.match(rule_1.regex);
                        if (matches) {
                            matched = matches[0];
                            action = rule_1.action;
                            break;
                        }
                    }
                }
            }
            if (!matches) {
                matches = [''];
                matched = '';
            }
            if (!action) {
                if (pos < lineLength) {
                    matches = [line.charAt(pos)];
                    matched = matches[0];
                }
                action = this._lexer.defaultToken;
            }
            if (matched === null) {
                break;
            }
            pos += matched.length;
            while (isFuzzyAction(action) && isIAction(action) && action.test) {
                action = action.test(matched, matches, state, pos === lineLength);
            }
            var result = null;
            if (typeof action === 'string' || Array.isArray(action)) {
                result = action;
            }
            else if (action.group) {
                result = action.group;
            }
            else if (action.token !== null && action.token !== undefined) {
                if (action.tokenSubst) {
                    result = substituteMatches(this._lexer, action.token, matched, matches, state);
                }
                else {
                    result = action.token;
                }
                if (action.goBack) {
                    pos = Math.max(0, pos - action.goBack);
                }
                if (action.switchTo && typeof action.switchTo === 'string') {
                    var nextState = substituteMatches(this._lexer, action.switchTo, matched, matches, state);
                    if (nextState[0] === '@') {
                        nextState = nextState.substr(1);
                    }
                    if (!findRules(this._lexer, nextState)) {
                        throw createError(this._lexer, 'trying to switch to a state \'' + nextState + '\' that is undefined in rule: ' + this._safeRuleName(rule));
                    }
                    else {
                        stack = stack.switchTo(nextState);
                    }
                }
                else if (action.transform && typeof action.transform === 'function') {
                    throw createError(this._lexer, 'action.transform not supported');
                }
                else if (action.next) {
                    if (action.next === '@push') {
                        if (stack.depth >= this._lexer.maxStack) {
                            throw createError(this._lexer, 'maximum tokenizer stack size reached: [' +
                                stack.state + ',' + stack.parent.state + ',...]');
                        }
                        else {
                            stack = stack.push(state);
                        }
                    }
                    else if (action.next === '@pop') {
                        if (stack.depth <= 1) {
                            throw createError(this._lexer, 'trying to pop an empty stack in rule: ' + this._safeRuleName(rule));
                        }
                        else {
                            stack = stack.pop();
                        }
                    }
                    else if (action.next === '@popall') {
                        stack = stack.popall();
                    }
                    else {
                        var nextState = substituteMatches(this._lexer, action.next, matched, matches, state);
                        if (nextState[0] === '@') {
                            nextState = nextState.substr(1);
                        }
                        if (!findRules(this._lexer, nextState)) {
                            throw createError(this._lexer, 'trying to set a next state \'' + nextState + '\' that is undefined in rule: ' + this._safeRuleName(rule));
                        }
                        else {
                            stack = stack.push(nextState);
                        }
                    }
                }
                if (action.log && typeof (action.log) === 'string') {
                    log(this._lexer, this._lexer.languageId + ': ' + substituteMatches(this._lexer, action.log, matched, matches, state));
                }
            }
            if (result === null) {
                throw createError(this._lexer, 'lexer rule has no well-defined action in rule: ' + this._safeRuleName(rule));
            }
            if (Array.isArray(result)) {
                if (groupMatching && groupMatching.groups.length > 0) {
                    throw createError(this._lexer, 'groups cannot be nested: ' + this._safeRuleName(rule));
                }
                if (matches.length !== result.length + 1) {
                    throw createError(this._lexer, 'matched number of groups does not match the number of actions in rule: ' + this._safeRuleName(rule));
                }
                var totalLen = 0;
                for (var i = 1; i < matches.length; i++) {
                    totalLen += matches[i].length;
                }
                if (totalLen !== matched.length) {
                    throw createError(this._lexer, 'with groups, all characters should be matched in consecutive groups in rule: ' + this._safeRuleName(rule));
                }
                groupMatching = {
                    rule: rule,
                    matches: matches,
                    groups: []
                };
                for (var i = 0; i < result.length; i++) {
                    groupMatching.groups[i] = {
                        action: result[i],
                        matched: matches[i + 1]
                    };
                }
                pos -= matched.length;
                continue;
            }
            else {
                if (result === '@rematch') {
                    pos -= matched.length;
                    matched = '';
                    matches = null;
                    result = '';
                }
                if (matched.length === 0) {
                    if (lineLength === 0 || stackLen0 !== stack.depth || state !== stack.state || (!groupMatching ? 0 : groupMatching.groups.length) !== groupLen0) {
                        continue;
                    }
                    else {
                        throw createError(this._lexer, 'no progress in tokenizer in rule: ' + this._safeRuleName(rule));
                    }
                }
                var tokenType = null;
                if (isString(result) && result.indexOf('@brackets') === 0) {
                    var rest = result.substr('@brackets'.length);
                    var bracket = findBracket(this._lexer, matched);
                    if (!bracket) {
                        throw createError(this._lexer, '@brackets token returned but no bracket defined as: ' + matched);
                    }
                    tokenType = sanitize(bracket.token + rest);
                }
                else {
                    var token_1 = (result === '' ? '' : result + this._lexer.tokenPostfix);
                    tokenType = sanitize(token_1);
                }
                var token = tokensCollector.emit(pos0 + offsetDelta, tokenType, stack);
                token.stack = stack;
                if (lastToken && lastToken != token) {
                    lastToken.value = line.slice(lastToken.offset - offsetDelta, pos0);
                }
                lastToken = token;
            }
        }
        if (lastToken && !lastToken.value) {
            lastToken.value = line.slice(lastToken.offset - offsetDelta, -1);
        }
        return MonarchLineStateFactory.create(stack);
    };
    return MonarchTokenizer;
}());
function findBracket(lexer, matched) {
    if (!matched) {
        return null;
    }
    matched = fixCase(lexer, matched);
    var brackets = lexer.brackets;
    for (var _i = 0, brackets_1 = brackets; _i < brackets_1.length; _i++) {
        var bracket = brackets_1[_i];
        if (bracket.open === matched) {
            return { token: bracket.token, bracketType: 1 };
        }
        else if (bracket.close === matched) {
            return { token: bracket.token, bracketType: -1 };
        }
    }
    return null;
}

// import * as monarch from './monarch'

var compiled = compile('imba',grammar);
const lexer = new MonarchTokenizer('imba',compiled);

function iter$(a){ return a ? (a.toIterable ? a.toIterable() : a) : []; }
const newline$1 = String.fromCharCode(172);

const GlobalVars = {
	global: 1,
	imba: 1,
	module: 1,
	window: 1,
	document: 1,
	exports: 1,
	console: 1,
	process: 1,
	parseInt: 1,
	parseFloat: 1,
	setTimeout: 1,
	setInterval: 1,
	setImmediate: 1,
	clearTimeout: 1,
	clearInterval: 1,
	clearImmediate: 1,
	globalThis: 1,
	isNaN: 1,
	isFinite: 1,
	__dirname: 1,
	__filename: 1
};

const ScopeTypes = {
	def: {closure: true,matcher: /(static)?\s*def ([\w\-\$]+\??)/},
	get: {closure: true,matcher: /(static)?\s*get ([\w\-\$]+\??)/},
	set: {closure: true,matcher: /(static)?\s*set ([\w\-\$]+\??)/},
	prop: {closure: true,matcher: /(static)?\s*prop ([\w\-\$]+\??)/},
	class: {closure: true,matcher: /class ([\w\-]+)/},
	tag: {closure: true,matcher: /tag ([\w\-]+)/},
	do: {closure: false},
	flow: {closure: false},
	root: {closure: true},
	element: {closure: false},
	value: {closure: false},
	style: {closure: true}
};

const TokenScopeTypes = {
	'tag.open': 'element',
	'tag.name.braces.open': 'value',
	'tag.flag.braces.open': 'value',
	'style.css.open': 'style'
};

const TokenContextRules = [
	[/(def|set) [\w\$]+[\s\(]/,'params'],
	[/(class) ([\w\-\:]+) <\s?([\w\-]*)$/,'superclass'],
	[/(tag) ([\w\-\:]+) <\s?([\w\-]*)$/,'supertag'],
	[/(def|set|get|prop|attr|class|tag) ([\w\-]*)$/,'naming'],
	[/\<([\w\-\:]*)$/,'tagname'],
	[/\\([\w\-\:]*)$/,'type']
// [/\.([\w\-\$]*)$/,'access']
];

class Variables {
	
	constructor(scope){
		
		this.scope = scope;
		this.tokens = [];
		this.map = {};
	}
	
	add(token){
		
		this.tokens.push(token);
		token.variable = token;
		token.varscope = this.scope;
		return this.map[token.value] = token;
	}
	
	lookup(name,deep = true){
		
		let res = this.map[name];
		if (deep && !(res) && this.scope.parent) {
			
			return this.scope.parent.variables.lookup(name);
		}		if (!(this.scope.parent) && !(res) && GlobalVars[name]) {
			
			let tok = {value: name,varscope: this.scope,type: 'variable.global'};
			return this.map[name] = tok.variable = tok;
		}		return res;
	}
}
class TokenScope {
	
	constructor({doc: doc,parent: parent,token: token,type: type,line: line}){
		var m;
		
		this.type = type;
		this.indent = line.indent;
		this.start = token.offset;
		this.token = token;
		this.end = null;
		this.endIndex = null;
		this.variables = new Variables(this);
		
		if (token.type.match(/(\w+)\.open/)) {
			
			this.pair = token.type.replace('open','close');
		}		
		if (m = (this.meta.matcher && line.lineContent.match(this.meta.matcher))) {
			
			this.name = m[m.length - 1];
			for (let $i = 0, $items = iter$(m.slice(1,-1)), $len = $items.length; $i < $len; $i++) {
				let mod = $items[$i];
				
				if (mod) { this[mod] = true; }			}		}		
		
		this.parent = parent;
		return this;
	}
	
	get meta(){
		
		return ScopeTypes[this.type] || ScopeTypes.flow;
	}
	
	sub(token,type,line){
		
		return new TokenScope({doc: null,parent: this,token: token,type: type,line: line});
	}
	
	get chain(){
		
		let items = [this];
		let scope = this;
		while (scope = scope.parent){
			
			items.unshift(scope);
		}		return items;
	}
	
	closest(match = null){
		
		let scope = this;
		while (scope){
			
			let typ = scope.meta;
			if (typeof match == 'string') {
				
				if (typ[match] || scope.type == match) { return scope }			}			scope = scope.parent;
		}		return null;
	}
	
	reopen(){
		
		this.end = null;
		this.endIndex = null;
		if (this.parent) this.parent.reopen();
		return this;
	}
	
	get closure(){
		
		return this.closest('closure');
		
	}
	toJSON(){
		
		return {type: this.type,start: this.start,end: this.end};
	}
}

class ImbaDocument {
	
	
	static tmp(content){
		
		return new this('file://temporary.imba','imba',0,content);
	}
	
	constructor(uri,languageId,version,content){
		
		this.uri = uri;
		this.languageId = languageId;
		this.version = version;
		this.content = content;
		this.connection = null;
		
		this.lineTokens = [];
		this.tokens = [];
		this.rootScope = new TokenScope({doc: this,token: {offset: 0,type: 'root'},type: 'root',line: {indent: -1},parent: null});
		this.head = this.start = {
			index: 0,
			line: 0,
			offset: 0,
			type: 'line',
			state: lexer.getInitialState(),
			context: this.rootScope,
			match: Token.prototype.match
		};
	}
	
	get lineCount(){
		
		return this.lineOffsets.length;
	}
	
	get lineOffsets(){
		
		return this._lineOffsets || (this._lineOffsets = computeLineOffsets(this.content,true));
	}
	
	getText(range = null){
		
		if (range) {
			
			var start = this.offsetAt(range.start);
			var end = this.offsetAt(range.end);
			return this.content.substring(start,end);
		}		return this.content;
	}
	
	getLineText(line){
		
		let start = this.lineOffsets[line];
		let end = this.lineOffsets[line + 1];
		return this.content.substring(start,end);
	}
	
	positionAt(offset){
		
		offset = Math.max(Math.min(offset,this.content.length),0);
		var lineOffsets = this.lineOffsets;
		var low = 0;
		var high = lineOffsets.length;
		if (high === 0) {
			
			return {line: 0,character: offset};
		}		while (low < high){
			
			var mid = Math.floor((low + high) / 2);
			if (lineOffsets[mid] > offset) {
				
				high = mid;
			} else {
				
				low = mid + 1;
			}		}		// low is the least x for which the line offset is larger than the current offset
		// or array.length if no line offset is larger than the current offset
		var line = low - 1;
		return {line: line,character: (offset - lineOffsets[line])};
	}
	
	offsetAt(position){
		
		if (position.offset) {
			
			return position.offset;
		}		
		var lineOffsets = this.lineOffsets;
		if (position.line >= lineOffsets.length) {
			
			return this.content.length;
		} else if (position.line < 0) {
			
			return 0;
		}		
		var lineOffset = lineOffsets[position.line];
		var nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this.content.length;
		return Math.max(Math.min(lineOffset + position.character,nextLineOffset),lineOffset);
	}
	
	overwrite(body,newVersion){
		
		this.version = newVersion || (this.version + 1);
		this.content = body;
		this._lineOffsets = null;
		this.invalidateFromLine(0);
		return this;
	}
	
	update(changes,version){
		
		// what if it is a full updaate
		// handle specific smaller changes in an optimized fashion
		// many changes will be a single character etc
		for (let i = 0, $items = iter$(changes), $len = $items.length; i < $len; i++) {
			let change = $items[i];
			
			if (editIsFull(change)) {
				
				this.overwrite(change.text,version);
				continue;
			}			
			var range = getWellformedRange(change.range);
			var startOffset = this.offsetAt(range.start);
			var endOffset = this.offsetAt(range.end);
			change.range = range;
			change.offset = startOffset;
			change.length = endOffset - startOffset;
			range.start.offset = startOffset;
			range.end.offset = endOffset;
			// console.log 'update',startOffset,endOffset,change.text,JSON.stringify(content)
			// content = content.substring(0, startOffset) + change.text + content.substring(endOffset, content.length)
			this.applyEdit(change,version,changes);
			
			var startLine = Math.max(range.start.line,0);
			var endLine = Math.max(range.end.line,0);
			var lineOffsets = this.lineOffsets;
			// some bug with these line offsets here
			// many items has no line offset changes at all?
			
			var addedLineOffsets = computeLineOffsets(change.text,false,startOffset);
			
			if ((endLine - startLine) === addedLineOffsets.length) {
				
				for (let k = 0, $ary = iter$(addedLineOffsets), $len = $ary.length; k < $len; k++) {
					let added = $ary[k];
					
					lineOffsets[k + startLine + 1] = addedLineOffsets[i];
				}			} else {
				
				if (addedLineOffsets.length < 10000) {
					
					lineOffsets.splice.apply(lineOffsets,[startLine + 1,endLine - startLine].concat(addedLineOffsets));
				} else {
					
					this._lineOffsets = lineOffsets = lineOffsets.slice(0,startLine + 1).concat(addedLineOffsets,lineOffsets.slice(endLine + 1));
				}			}			
			var diff = change.text.length - (endOffset - startOffset);
			if (diff !== 0) {
				
				let k = startLine + 1 + addedLineOffsets.length;
				while (k < lineOffsets.length){
					
					lineOffsets[k] = lineOffsets[k] + diff;
					k++;
				}			}		}		
		return this.updated(changes,version);
	}
	
	applyEdit(change,version,changes){
		
		// apply textual changes
		this.content = this.content.substring(0,change.range.start.offset) + change.text + this.content.substring(change.range.end.offset,this.content.length);
		
		let line = change.range.start.line;
		let caret = change.range.start.character + 1;
		this.invalidateFromLine(line);
		if (changes.length == 1 && change.text == '<') {
			
			let text = this.getLineText(line);
			let matcher = text.slice(0,caret) + '' + text.slice(caret);
			
			if (matcher.match(/(^\t*|[\=\>]\s+)\<\(?!\s*\>)/)) {
				
				if (this.connection) {
					
					this.connection.sendNotification('closeAngleBracket',{uri: this.uri});
				}			}		}		return;
	}
	
	
	updated(changes,version){
		
		this.version = version;
		return this;
	}
	
	invalidateFromLine(line){
		
		if (this.head.line >= line) {
			
			let state = this.lineTokens[Math.max(line - 1,0)] || this.start;
			if (state) {
				
				this.tokens.length = state.index;
				this.head = state;
				state.context.reopen();
			}		}		return this;
	}
	
	
	after(token){
		
		let idx = this.tokens.indexOf(token);
		return this.tokens[idx + 1];
	}
	
	matchToken(token,match){
		
		if (match instanceof RegExp) {
			
			return token.type.match(match);
		} else if (typeof match == 'string') {
			
			return token.type == match;
		}		return false;
	}
	
	before(token,match,flat){
		
		let idx = this.tokens.indexOf(token);
		if (match) {
			
			while (idx > 0){
				
				let tok = this.tokens[--idx];
				if (this.matchToken(tok,match)) {
					
					return tok;
				}			}		}		return this.tokens[idx - 1];
	}
	
	getTokenRange(token){
		
		return {start: this.positionAt(token.offset),end: this.positionAt(token.offset + token.value.length)};
	}
	
	getTokensInScope(scope){
		
		let start = this.tokens.indexOf(scope.token);
		let end = scope.endIndex || this.tokens.length;
		let i = start;
		let parts = [];
		while (i < end){
			
			let tok = this.tokens[i++];
			if (tok.scope && tok.scope != scope) {
				
				parts.push(tok.scope);
				i = tok.scope.endIndex + 1;
			} else {
				
				parts.push(tok);
			}		}		return parts;
	}
	
	getTokenAtOffset(offset,forwardLooking = false){
		
		let pos = this.positionAt(offset);
		this.getTokens(pos);// ensure that we have tokenized all the way here
		let line = this.lineTokens[pos.line];
		let idx = line.index;
		let token;
		let prev;
		// find the token
		while (token = this.tokens[idx++]){
			
			if (forwardLooking && token.offset == offset) {
				
				return token;
			}			
			if (token.offset >= offset) { break; }			prev = token;
		}		return prev || token;
	}
	
	getSemanticTokens(){
		
		this.getTokens();
		return this.tokens.filter(function(_0) { return !(!(_0.variable)); });
	}
	
	getContextAtOffset(offset,forwardLooking = false){
		var start, elscope;
		
		let pos = this.positionAt(offset);
		let token = this.getTokenAtOffset(offset,forwardLooking);
		let index = this.tokens.indexOf(token);
		let line = this.lineTokens[pos.line];
		let prev = this.tokens[index - 1];
		let next = this.tokens[index + 1];
		
		let context = {
			offset: offset,
			position: pos,
			token: token,
			line: line.lineContent,
			textBefore: line.lineContent.slice(0,offset - line.offset),
			textAfter: line.lineContent.slice(offset - line.offset),
			mode: token.stack ? token.stack.state : '',
			scope: line.context
		};
		
		// context.tokenBefore = offset >= token.offset
		
		let scope = context.scope;
		let mode = context.mode;
		let indent = context.indent = context.textBefore.match(/^\t*/)[0].length;
		
		let m;
		if (m = token.type.match(/regexp|string|comment|decorator/)) {
			
			mode = m[0];
			context.nested = true;
		} else if (mode.match(/style/) || mode.match(/tag\.(\w+)/)) ; else {
			
			while (scope.indent >= indent && !(scope.pair)){
				
				scope = scope.parent;
			}			
			if (mode.match(/(\.(var|let|const|param))/)) {
				
				mode = 'varname';
			} else if (m = token.type.match(/white\.(\w+)/)) {
				
				mode = m[1];
			} else {
				
				for (let $i = 0, $items = iter$(TokenContextRules), $len = $items.length; $i < $len; $i++) {
					let rule = $items[$i];
					
					if (context.textBefore.match(rule[0])) {
						
						mode = rule[1];break;
					}				}			}		}		
		if (mode == 'string' && context.textBefore.match(/import |from |require(\(|\s)/)) {
			
			mode = 'filepath';
		}		
		let vars = context.vars = [];
		
		// Start from the first scope and collect variables up to this token
		if (start = line.context.closure) { // line.scopes[line.scopes.length - 1]
			
			let i = Math.max(this.tokens.indexOf(start.token),0);
			var scop;while (i <= index){
				
				let tok = this.tokens[i++];
				if (scop = tok.scope) {
					
					if (scop.endIndex != null && scop.endIndex < index) {
						
						i = scop.endIndex;
						continue;
					}					scope = scop;
				}				
				if (tok.type.match(/variable/)) {
					
					vars.push(tok);
				}			}		}		
		if (!(context.nested)) {
			
			while (scope.indent >= indent && !(scope.pair) && (scope.start < line.offset)){
				
				scope = scope.parent;
			}		}		
		
		if (elscope = scope.closest('element')) {
			
			let parts = this.getTokensInScope(elscope);
			let tagName = '';
			let tagNameStart;
			let tagNameEnd;
			for (let $i = 0, $items = iter$(parts), $len = $items.length; $i < $len; $i++) {
				let part = $items[$i];
				
				if (part.type == 'tag.name') {
					
					tagName += part.value;
					tagNameStart || (tagNameStart = part);
					tagNameEnd = part;
				}				if (part.token && part.token.type == 'tag.name.braces.open') {
					
					tagName += '*';
					tagNameStart || (tagNameStart = part.token);
					tagNameEnd = part.token;
				}			}			
			elscope.name = tagName;
			
			
		}		if (scope.type == 'element') {
			
			// not inside anywhere special?
			context.tagName = this.after(scope.token);
		}		
		context.scope = scope;
		context.mode = mode;
		context.tag = scope.closest('element');
		context.tagScope = scope.closest('tag');
		context.classScope = scope.closest('class');
		
		if (context.tag && context.tag.name == 'self') {
			
			if (scope.closest('tag')) {
				
				context.tag.name = scope.closest('tag').name;
			}		}		
		if (context.mode.match(/^(var_value|object_value|root)/)) {
			
			if (context.textBefore.match(/([^\.]\.\.|[^\.]\.)([\w\-\$]*)$/)) {
				
				context.mode = 'access';
			}		}		return context;
		
	}
	
	// This is essentially the tokenizer
	getTokens(range){
		
		var codelines = this.content.split('\n');
		
		var tokens = this.tokens;
		var toLine = range ? range.line : ((this.lineCount - 1));
		var lineCount = this.lineCount;
		
		var $head;while (this.head.line <= toLine){
			
			let i = this.head.line;
			let offset = this.head.offset;
			let code = codelines[this.head.line];
			
			let indent = 0;
			while (code[indent] === '\t'){
				
				indent++;
			}			
			let lineToken = this.lineTokens[i] = {
				offset: offset,
				state: this.head.state,
				stack: this.head.state.stack,
				line: i,
				indent: indent,
				type: 'line',
				meta: this.head.state.stack,
				lineContent: code,
				match: Token.prototype.match,
				value: i ? '\n' : '',
				index: tokens.length,
				context: this.head.context
			};
			
			let scope = this.head.context;
			
			if ((code[indent] || i == lineCount) && !(lineToken.stack.state.match(/string|regexp/))) {
				
				// Need to track parens etc as well
				while (scope){
					
					if (scope.indent >= indent && !(scope.pair)) {
						
						scope.end = offset;
						scope.endIndex = lineToken.index;
						scope = scope.parent;
					} else {
						
						break;
					}				}			}			
			tokens.push(lineToken);
			
			let lexed = lexer.tokenize(code + newline$1,this.head.state,offset);
			let lastVarRef = null;
			
			for (let i = 0, $items = iter$(lexed.tokens), $len = $items.length, variable; i < $len; i++) {
				let tok = $items[i];
				
				if (tok.type == 'newline') { continue; }				// continue if tok.type == 'lookahead.imba'
				let next = lexed.tokens[i + 1];
				let to = next ? ((next.offset - offset)) : 1000000;
				
				let match;
				
				if (match = tok.type.match(/keyword\.(class|def|set|get|prop|tag|if|for|while|do|elif|unless|try|catch|else)/)) {
					
					tok.scope = scope = scope.sub(tok,match[1],lineToken);
				} else if (TokenScopeTypes[tok.type]) {
					
					tok.scope = scope = scope.sub(tok,TokenScopeTypes[tok.type],lineToken);
				} else if (tok.type == scope.pair) {
					
					scope.end = tok.offset;
					scope.endIndex = tokens.length;
					scope = scope.parent;
				}				
				if (tok.type.match(/^variable/)) {
					
					scope.variables.add(tok);
					lastVarRef = tok;
				} else if (tok.type == 'identifier') {
					
					if (variable = scope.variables.lookup(tok.value)) {
						
						tok.variable = variable;
						
						if (lastVarRef && lastVarRef.variable == variable) {
							
							let between = code.slice(lastVarRef.offset + lastVarRef.value.length - offset,tok.offset - offset);
							// console.log 'same variable',lastVarRef,variable,tok,JSON.stringify(between),next
							if (between.match(/^\s*\=\s*$/) && (!(next) || code.slice(to).match(/^\s*[\,\)]/) || next.type == 'newline')) {
								
								if (lastVarRef == variable) {
									
									tok.variable = null;
								} else {
									
									lastVarRef.variable = null;
								}							}						}						
						lastVarRef = tok;
					}				}				
				tokens.push(tok);
			}			
			this.head.context = scope;
			this.head.line++;
			($head = this.head).offset = $head.offset + code.length + 1;
			this.head.state = lexed.endState;
		}		return tokens;
	}
	
	
	migrateToImba2(){
		
		let source = this.content;
		source = source.replace(/\bdef self\./g,'static def ');
		source = source.replace(/\b(var|let|const) def /g,'def ');
		source = source.replace(/\?\./g,'..');
		
		source = source.replace(/def ([\w\-]+)\=/g,'set $1');
		
		source = source.replace(/do\s?\|([^\|]+)\|/g,'do($1)');
		
		source = source.replace(/(prop) ([\w\-]+) (.+)$/gm,function(m,typ,name,rest) {
			var $v_, $1;
			
			let opts = {};
			rest.split(/,\s*/).map(function(_0) { return _0.split(/\:\s*/); }).map(function(_0) { return opts[_0[0]] = _0[1]; });
			let out = ("" + typ + " " + name);
			
			if (opts.watch && opts.watch[0].match(/[\'\"\:]/)) {
				
				out = ("@watch(" + (opts.watch) + ") " + out);
			} else if (opts.watch) {
				
				out = ("@watch " + out);
			}			
			((($v_ = opts.watch),delete opts.watch, $v_));
			
			if (opts.default) {
				
				out = ("" + out + " = " + (opts.default));
				((($1 = opts.default),delete opts.default, $1));
			}			
			if (Object.keys(opts).length) {
				
				console.log('more prop values',m,opts);
			}			return out;
		});
		
		let doc = ImbaDocument.tmp(source);
		let tokens = doc.getTokens();
		let ivarPrefix = '';
		
		for (let i = 0, $items = iter$(tokens), $len = $items.length; i < $len; i++) {
			let token = $items[i];
			
			
			let next = tokens[i + 1];
			let {value: value,type: type,offset: offset} = token;
			let end = offset + value.length;
			if (type == 'operator.dot.legacy') {
				
				value = '.';
				if (next) { next.access = true; }			}			
			if (type == 'operator.spread.legacy') {
				
				value = '...';
			}			
			if (type == 'identifier.tagname') {
				
				if (value.indexOf(':') >= 0) {
					
					value = value.replace(':','-');
				}			}			if (type == 'identifier.def.propname' && value == 'initialize') {
				
				value = 'constructor';
			}			
			if (type == 'decorator' && !(source.slice(end).match(/^\s(prop|def|get|set)/))) {
				
				value = ivarPrefix + value.slice(1);
			}			
			if (type == 'property') {
				
				if (value[0] == '@') {
					
					value = value.replace(/^\@/,ivarPrefix);
					token.access = true;
				} else if (value == 'len') {
					
					value = 'length';
				} else if ((/^(\n|\s\:|\)|\,|\.)/).test(source.slice(end)) && !(token.access)) {
					
					if (value[0] == value[0].toLowerCase()) {
						
						value = value + '!';
					}				}			}			
			if (type == 'identifier' && !(token.access) && value[0] == value[0].toLowerCase() && value[0] != '_') {
				
				if (!(token.variable) && (/^(\n|\s\:|\)|\,|\.)/).test(source.slice(end)) && value != 'new') {
					
					value = value + '!';
				}			}			
			token.value = value;
		}		
		return tokens.map(function(_0) { return _0.value; }).join('');
	}
}

export { ImbaDocument };
